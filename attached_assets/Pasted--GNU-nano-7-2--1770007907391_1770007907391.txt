  GNU nano 7.2                                                                                                                                                                                                                                                                                                                                                                                                 /opt/alessia-voice/vps-voice-bridge/src/voice-bridge-server.ts                                                                                                                                                                                                                                                                                                                                                                                                           
import { WebSocketServer, WebSocket } from 'ws';
import { createServer, type IncomingMessage } from 'http';
import { parse as parseUrl } from 'url';
import { config } from './config.js';
import { logger } from './logger.js';
import { sessionManager } from './session-manager.js';
import { ReplitWSClient } from './replit-ws-client.js';
import { convertForGemini, convertFromGemini } from './audio-converter.js';
import { fetchCallerContext, notifyCallStart, notifyCallEnd } from './caller-context.js';

const log = logger.child('SERVER');

let pendingCallId: string | null = null;
let pendingCallTimer: NodeJS.Timeout | null = null;

export function setExpectedCallId(uuid: string): void {
  pendingCallId = uuid;
  log.info(`Expecting connection for Call ID: ${uuid}`);
  if (pendingCallTimer) clearTimeout(pendingCallTimer);
  pendingCallTimer = setTimeout(() => {
    if (pendingCallId === uuid) pendingCallId = null;
  }, 5000);
}

interface AudioStreamStartMessage {
  event: 'start';
  call_id: string;
  caller_id: string;
  called_number: string;
  codec: 'PCMU' | 'L16';
  sample_rate: number;
}

interface AudioStreamStopMessage {
  event: 'stop';
  call_id: string;
  reason: string;
}

type AudioStreamMessage = AudioStreamStartMessage | AudioStreamStopMessage;

function firstQueryValue(v: unknown): string {
  if (Array.isArray(v)) return typeof v[0] === 'string' ? v[0] : '';
  return typeof v === 'string' ? v : '';
}

function isLocalNetwork(clientIp: string): boolean {
  return clientIp === '127.0.0.1' || clientIp === '::1' || clientIp === '::ffff:127.0.0.1' ||
    clientIp.startsWith('172.17.') || clientIp.startsWith('172.18.') || clientIp.startsWith('10.');
}

export function startVoiceBridgeServer(): void {
  const server = createServer((req, res) => {
    res.writeHead(404);
    res.end('Not Found');
  });

  const wss = new WebSocketServer({ server });

  wss.on('connection', (ws: WebSocket, req: IncomingMessage) => {
    const clientIp = req.socket.remoteAddress || 'unknown';
    const url = parseUrl(req.url || '', true);
    const q = url.query;

    log.info(`New WebSocket connection`, { clientIp });

    let currentSessionId: string | null = null;
    let callId = firstQueryValue(q.call_id);

    if (!callId && pendingCallId) {
      callId = pendingCallId;
      pendingCallId = null;
      if (pendingCallTimer) clearTimeout(pendingCallTimer);
    }

    if (callId) {
      const callerId = firstQueryValue(q.caller_id) || 'unknown';

      // *** FORZIAMO L16 A 16000Hz (Configurazione Stabile) ***
      const startMsg: AudioStreamStartMessage = {
        event: 'start',
        call_id: callId,
        caller_id: callerId,
        called_number: '9999',
        codec: 'L16',
        sample_rate: 16000,
      };

      console.log(`[DEBUG] üìû CHIAMATA RILEVATA: ID=${callId} | Codec=${startMsg.codec}`);

      handleCallStart(ws, startMsg).then((sid) => {
        currentSessionId = sid;
      }).catch((e) => {
        console.error(`[DEBUG] ‚ùå Errore Init Sessione: ${e.message}`);
        ws.close(1011, 'Session init failed');
      });
    }

    ws.on('message', (data: Buffer, isBinary: boolean) => {
      if (isBinary && currentSessionId) {
        handleAudioData(currentSessionId, data);
      }
    });

    ws.on('close', () => {
      if (currentSessionId) {
        console.log(`[DEBUG] üîå WebSocket Chiuso (Sessione: ${currentSessionId})`);
        const session = sessionManager.getSession(currentSessionId);
        if (session) handleCallStop(session.callId, 'websocket_closed');
      }
    });
  });

  server.listen(config.ws.port, config.ws.host, () => {
    log.info(`Voice Bridge Server started on port ${config.ws.port}`);
  });
}

async function handleCallStart(ws: WebSocket, message: AudioStreamStartMessage): Promise<string> {
  const session = sessionManager.createSession(
    message.call_id, message.caller_id, message.called_number,
    message.codec, message.sample_rate, ws
  );

  await notifyCallStart(session.id, message.caller_id, message.called_number);

  const replitClient = new ReplitWSClient({
    sessionId: session.id,
    callerId: message.caller_id,

    // *** LOG DELL'AUDIO IN ENTRATA ***
    onAudioResponse: (audio) => {
        console.log(`[DEBUG] üé§ AUDIO DA GEMINI: ${audio.length} bytes`);
        sendAudioToFreeSWITCH(session.id, audio);
    },

    // *** LOG DEL TESTO ***
    onTextResponse: (text) => {
        console.log(`[DEBUG] ü§ñ GEMINI DICE: "${text}"`);
        log.debug(`AI: ${text}`);
    },

    onError: (err) => {
        console.error(`[DEBUG] ‚ùå Errore Replit: ${err.message}`);
        log.error(`Replit Error`, { error: err.message });
    },
    onClose: () => log.info(`Replit closed`),
  });

  await replitClient.connect();
  sessionManager.setReplitClient(session.id, replitClient);
  sessionManager.updateSessionState(session.id, 'active');
  return session.id;
}

function handleAudioData(sessionId: string, audioData: Buffer): void {
  const session = sessionManager.getSession(sessionId);
  if (!session || session.state !== 'active') return;
  // Convertiamo l'audio per Gemini (Input verso AI)
  const pcm = convertForGemini(audioData, session.codec, session.sampleRate);
  session.replitClient?.sendAudio(pcm);
}

// *** FUNZIONE DI INVIO CON LOG DETTAGLIATI ***
function sendAudioToFreeSWITCH(sessionId: string, audio: Buffer): void {
  const session = sessionManager.getSession(sessionId);

  if (!session?.fsWebSocket || session.fsWebSocket.readyState !== WebSocket.OPEN) {
      console.log('[DEBUG] ‚ö†Ô∏è Impossibile inviare: WebSocket assente o chiuso');
      return;
  }

  // 1. Convertiamo l'audio (il converter ora rispetta L16)
  const fsAudio = convertFromGemini(audio, session.codec, session.sampleRate);

  // 2. Chunking a 20ms (640 bytes per L16 16k)
  const CHUNK_SIZE = 640;
  let chunks = 0;

  for (let i = 0; i < fsAudio.length; i += CHUNK_SIZE) {
    const chunk = fsAudio.slice(i, i + CHUNK_SIZE);
    session.fsWebSocket.send(chunk, { binary: true });
    chunks++;
  }

  // 3. Logghiamo l'invio
  console.log(`[DEBUG] üöÄ Inviati ${chunks} pacchetti (${fsAudio.length} bytes) a FreeSWITCH`);
}

function handleCallStop(callId: string, reason: string): void {
  const session = sessionManager.getSessionByCallId(callId);
  if (!session) return;
  const duration = Date.now() - session.startTime.getTime();
  notifyCallEnd(session.id, duration, session.audioStats.bytesIn, session.audioStats.bytesOut, reason);
  sessionManager.endSession(session.id, reason);