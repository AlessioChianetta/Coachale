Il piano è molto buono e, soprattutto, va dritto a risolvere tutti e 3 i problemi che hai (stato volatile, niente atomicità, classifier senza contesto). Ti segnalo solo le 2–3 cose che mancano per renderlo davvero “a prova di produzione” e un paio di correzioni operative.

1) La UPDATE atomica sul token non basta: serve un “muro” anche sullo slot

Il rischio rimane se due utenti ottengono due token diversi per lo stesso (consultant_id, start_at).

Quindi oltre alla unique su consultations(consultant_id, scheduled_at) (hard safety) ti conviene aggiungere anche una unique per gli hold (soft safety) su pending_bookings:

Se sei su Postgres (consigliato)

Usa un partial unique index:

unico solo quando status = 'awaiting_confirm'

Esempio (concetto):

UNIQUE (consultant_id, start_at) WHERE status='awaiting_confirm'

Così puoi avere storico di expired/cancelled senza blocchi.

Se NON sei su Postgres

Hai 2 alternative solide:

Lock transazionale sullo slot (advisory lock o equivalente) in proposeBooking e confirmBooking

Generated column “is_active_hold” (se DB lo supporta) e unique su (consultant_id, start_at, is_active_hold) dove is_active_hold=1 solo per awaiting_confirm

Senza una di queste, il double booking può ancora succedere in concorrenza.

2) Correzione in Fase 2.2: il token va generato PRIMA dell’INSERT

Nel piano hai scritto “Commit → Generare token crypto e salvare”.
Ma se token è PK, devi:

generare token

poi INSERT pending_bookings(token, ...)

commit

3) Timestamp e timezone: salva start_at in UTC (timestamptz) e converti in UI

Dato che sei in Europe/Rome, fai così:

parse date/time dal tool in timezone Europe/Rome

converti a UTC

salva start_at come timestamptz (o equivalente)

Questo ti evita bug su DST e confronti.

4) confirmBooking: gestisci la unique constraint di consultations come “errore business”

Nel flusso:

UPDATE pending → ok

INSERT consultations → può fallire per unique (consultant_id, scheduled_at) se lo slot è già preso (race condition)

Quando succede:

ritorna un errore strutturato tipo:

SLOT_TAKEN

e aggiorna pending a cancelled o expired (per non lasciarlo “confirmed” senza consultazione).

5) Fallback senza token: “latest pending per conversation” sì, ma con vincoli

La tua Fase 3.3 è giusta. Due dettagli importanti:

ordina per created_at DESC

verifica sempre client_id (come hai scritto) e idealmente anche consultant_id se è una chat con consultant specifico

6) La Fase 4 è il fix esatto per “esce dal tool”

Nel tuo ai-service.ts oggi hai:

pendingBookingToken: undefined e hasPendingBooking: false (TODO)

e il classifier viene chiamato solo se match regex/keywords

Quindi quando l’utente risponde “ok/va bene”:

non matcha keywords

non parte classifier

isConsultationQuery=false

tool disabilitati → il modello “scappa”

Con getPendingBookingState() + sticky tool mode:

anche “ok” resta nel flow

booking_confirm non viene più bloccato (perché hai pendingBookingToken)

7) Aggiorna davvero il prompt del classifier con contesto (non solo gating)

Oggi il contesto non entra nel prompt, serve solo per bloccare booking_confirm.

Quando hasPendingBooking=true, conviene aggiungere una riga nel prompt tipo:

Context: hasPendingBooking=true

Così “ok” diventa molto più stabile come booking_confirm.

8) Cron expiry: ok, ma falla “best effort”, non “single point of truth”

Va benissimo un job ogni 1–2 minuti.
In più, confirmBooking dovrebbe comunque trattare expires_at < now() come scaduto anche se il cron non è ancora passato.

In sintesi: cosa cambierei al tuo piano

Il piano va bene così com’è, con queste aggiunte/minime modifiche:

Aggiungi protezione slot-level su pending_bookings (partial unique index o lock)

Token prima dell’INSERT

Gestione unique violation su insert consultations (errore business + cleanup pending)

start_at in UTC e conversione lato output

Context nel prompt del classifier, non solo gating